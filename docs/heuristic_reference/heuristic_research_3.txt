Designing a Heuristic Boundary Detector for a PDF Splitter
Understanding the Challenge
Splitting a multi-document PDF by detecting document boundaries is difficult because the documents can vary widely in type and format. In a law firm context, a single PDF might contain anything from emails and letters to contracts, forms, invoices, or handwritten notes. As one developer noted, with “multiple types of documents, different correspondents... All documents are dynamic,” it’s hard to find one simple pattern that fits every casegithub.com. This means a heuristic approach must be both broadly applicable and robust to variations – a non-trivial design challenge.
Designing the Heuristic Module
A good approach is to combine textual cues, layout/structural cues, and metadata heuristics to flag probable document breaks. Here are some strategies to consider:
    • First-Page Indicators: Many document types have distinctive features on their first page. For example, letters and emails often start with headers or addresses (e.g. sender/receiver info, dates, subject lines), and reports or contracts might begin with a title or letterhead. A practitioner observed that “typical documents… usually have some sort of header on the first page, [like] a block with addresses, subject, [or] name of a vendor”github.com. Your heuristic module could scan for such features at the top of a page:
        ◦ Presence of addresses or greeting (e.g. a line starting with “Dear” or an address block) likely marks a beginning of a letter.
        ◦ Email headers (keywords like “From:”, “To:”, “Subject:”) at the top of a page strongly indicate the start of an email document.
        ◦ Titles or letterheads in larger or bold font on a page, especially if followed by normal text, can signal a new document (common in reports, memos, etc.).
        ◦ Keywords that often start documents (like “Complaint”, “Affidavit”, “Invoice #”, etc., depending on context) could be used as triggers for a new document.
    • End-of-Document Cues: Similarly, detect patterns that suggest a page is the end of a document:
        ◦ Signature lines or closings (e.g. a line with a person’s name, signature image, or “Sincerely,”) near the bottom of a page may mean the document ended there.
        ◦ Blank or near-blank pages – a completely or mostly empty page is often used as a separator or indicates nothing followed, so it’s a natural break point.
        ◦ Excess whitespace at the bottom: if a page has an unusual amount of blank space after some content (e.g. half the page is empty), it might mean the document’s content ended mid-page (common when a letter or memo doesn’t fill a page), implying a boundary before the next page.
    • Layout and Formatting Changes: Heuristics can exploit abrupt changes in layout between pages:
        ◦ Page numbering resets: If the OCR’d text on one page shows “Page 1 of X” or any page number that resets on the next page, that’s a clear boundary indicator. A research study found that using “layout and page numbering features” was highly effective, yielding ~95.6% accuracy in separating batch-scanned documentswenku.baidu.com.
        ◦ Header/footer patterns: If one page has a certain header or footer (e.g. a running title or page number) and the next page lacks it or has a different pattern, that could indicate a new document. For instance, a multi-page document might have a consistent header or footer on each page (like a case name or an email chain footer), whereas a new document’s first page might not.
        ◦ Font and margin differences: A new document might use different fonts, font sizes, or margin settings. If page N+1 has noticeably different styling (say, page N is an email printout in a certain font, but page N+1 is a scanned form with typed fields), that transition might be a boundary.
        ◦ Content density and structure: Compare the overall structure of two adjacent pages:
            ▪ One page might be a dense block of text (paragraphs), and the next page might be a form with multiple fields or a table, etc. A stark difference in structure suggests they belong to different documents.
            ▪ Look for lines or elements that span the full width on one page but not on the next, or vice versa (e.g. a table or list continues vs. a narrative text starts).
            ▪ If a page has a table of contents or index (uncommon in legal discovery but possible), that’s likely the start of a new document (like a report).
    • Textual Continuity Heuristics: Without invoking a full LLM, simpler text-based checks can indicate if two pages belong together:
        ◦ Sentence flow: Check the last line of page N and the first line of page N+1. If page N ends in the middle of a sentence (or a hyphenated word) and page N+1 starts by completing that sentence, they are almost certainly the same document. Conversely, if page N ends cleanly (period or signature) and page N+1 starts with a new topic or a capital letter salutation, that suggests a break.
        ◦ Topic similarity: Use keyword overlap or even a lightweight embedding approach to gauge similarity between pages. If page N and N+1 share a lot of content words or proper nouns (e.g. both pages mention the same project name or individuals), they likely belong to the same document. A drastic change in vocabulary or subject from one page to the next might signal a new document.
        ◦ OCR metadata cues: If using OCR, track certain fields. For example, emails often have dates and times at the top; a jump from one email’s timestamp to a completely different timestamp on the next page is a clue.
    • PDF Metadata and Properties: Sometimes the PDF itself contains clues, especially in combined scans:
        ◦ Page dimensions or scan settings: As noted in one case, different sets of pages had slightly different dimensions (e.g. tiny variations in the MediaBox size for each scan job). In a 223-page example, pages 1–2 shared one size, pages 3–5 another, etc., aligning with document boundariesstackoverflow.comstackoverflow.com. Checking if the page width/height (from PDF metadata) changes between pages can be an immediate heuristic – if page 5 is 595x842 pts and page 6 is 591x835 pts, that likely marks a new scan (and thus a new document). “There is some commonality in sequential pages”, and grouping pages by identical size can thus approximate the original document splitsstackoverflow.com (with caution for edge cases where size might coincidentally repeat).
        ◦ Creator/Producer metadata: If the PDF was assembled from multiple source files, sometimes the PDF metadata per page (if accessible via libraries) might show different producers or creation times. For example, pages that were originally an MS Word document vs. a scanned image might carry different metadata. A change could hint at a boundary.
        ◦ Bookmarks or outlines: Though the user in a StackOverflow query found bookmarks not useful for his case, in some PDFs bookmarks or embedded tags could indicate document sections. It’s a long shot, but worth checking if the PDF has any outline entries or annotations that correspond to breakpoints.
    • Confidence and “Fuzzy” Rules: Given the variety of documents, it may be wise to assign a heuristic score rather than absolute yes/no for each potential boundary. For example, each cue above can add or subtract from a “boundary likelihood” score for the junction between page N and N+1:
        ◦ e.g. “New email header found” = strong positive weight for a boundary,
        ◦ “Sentence flows naturally across pages” = strong negative weight (i.e. likely continuous),
        ◦ “Same page size and layout style” = negative weight (same document),
        ◦ “Large blank gap at end of page” = positive weight (possible break),
        ◦ and so on.
Designing the heuristic module in this weighted way allows it to be tunable and to express uncertainty. You might not catch everything with one rule, but a combination of signals can be quite accurate for many cases. Research shows that even simple features can go far – one algorithm combining text/layout cues managed to correctly split nearly all documents in a test batchwenku.baidu.com. The key is to leverage multiple features in tandem.
Maintainability: Since your use cases are broad, expect to refine these heuristics over time. It’s a good idea to log instances where the heuristics guessed wrong and either adjust the rules or incorporate those edge cases. Keeping the heuristic logic modular (perhaps as a set of functions or checks) will make it easier to update when you encounter a new document pattern.
Integration Strategy: Heuristics vs. LLM vs. Visual
Now, how should you integrate this heuristic detector with the more resource-intensive LLM and visual methods? There are a few approaches:
    • Heuristics as a First Pass (Filter): This strategy uses the heuristics to catch obvious boundaries and continuations, reducing the work for the LLM/visual detectors. The idea is to quickly handle the easy cases:
        ◦ If the heuristic module is very confident that a break does or does not occur between pages, you can act on that immediately (e.g. mark a split or merge those pages).
        ◦ Only for the unclear or borderline cases would you invoke the heavier detectors. For example, if the heuristic score for a boundary is intermediate (or conflicting signals), call the LLM boundary check on that page transition, or use the visual layout analysis, to get a second opinion.
        ◦ This cascaded approach can save a lot of time. Most straightforward cases (like obvious email boundaries or blank-page separators) skip the CPU-heavy analysis. The LLM and visual models are only tasked with the hard cases that the heuristic isn’t sure about.
        ◦ Pros: Efficient use of resources – fast handling of simple cases, fewer calls to LLM. In practice, heuristics can dramatically narrow down the number of candidate breakpoints that need further analysis.
        ◦ Cons: The overall accuracy is only as good as the heuristics for the first pass. If a boundary is subtle and the heuristics miss it (or falsely flag one), it might slip through or require complex logic to catch later. So, you’d need to be careful that the heuristic’s “confidence” threshold is tuned such that truly ambiguous cases do get sent to the LLM/visual stage, rather than being wrongly decided.
    • Heuristics as One Vote in an Ensemble: Another approach is to treat each detection method (heuristic, LLM, visual) as providing an independent “vote” or confidence score for each possible boundary, then combine them to make the final decision. In effect, all three methods would analyze the document in parallel (or in sequence but without any one being a hard filter) and you'd reconcile their outputs:
        ◦ For each page-to-page transition, you could collect: H (heuristic score), L (LLM prediction), V (visual layout change score).
        ◦ Define a rule for final boundary decision, for example: a boundary is marked if at least two out of three methods strongly indicate a break, or if one method’s confidence is above a high threshold.
        ◦ This voting/ensemble method can improve accuracy by compensating for one method’s weaknesses with another’s strengths. For instance, if the heuristics and visual analysis both suggest a boundary but the LLM is unsure, the ensemble could still decide “boundary” by majority. Conversely, if heuristics alone says “break” but both LLM and visual think the pages flow together, the final decision would be “no break” (preventing a false split).
        ◦ Pros: Maximizes accuracy and robustness. Each method acts as a safety net for the others. This is important because, as one expert noted, “correcting errors in page separation is way more tedious” than other post-processing fixesgithub.com – so you want to avoid mistakes. An ensemble is less likely to make a gross error if at least one method catches the issue.
        ◦ Cons: This can be slow, since you’re essentially running all methods on all page transitions. It also adds complexity in how to weight or trust each signal. Not every method will have a clear yes/no output (LLM might give a probability, heuristics a score, etc.), so you’ll need a strategy to normalize these. Moreover, if the methods disagree frequently, defining the tiebreaking logic can be tricky and might require iterative tuning.
    • Hybrid Approach: You don’t have to pick strictly one or the other; a practical implementation can combine the above. For example:
        ◦ Primary pass with heuristics: Quickly identify likely first pages of new documents (and conversely, likely continuations). For example, if heuristics detect a prototypical email header on page 10, you tentatively mark a split before page 10.
        ◦ Validation with other methods: For each tentative boundary (and perhaps any spots the heuristics were uncertain about), run the LLM boundary check on the surrounding pages. The LLM can confirm the split by seeing if the text context truly shifts. If the LLM disagrees with a heuristic-based boundary (e.g., heuristics thought it’s a new doc, but LLM says the text flows logically), that boundary would be flagged for further review (maybe then you’d involve the visual detector or apply a more strict rule).
        ◦ Visual analysis as a tie-breaker or secondary check: The visual layout method (once implemented) could be used on boundaries where text-based methods (heuristic or LLM) don’t confidently agree. The visual cues (like margin differences, presence of a big title, etc.) could add another vote. For instance, if heuristics are 50/50 and LLM is unsure, but visually you detect a big change in formatting, that could tip the decision towards a split.
In essence, a reasonable implementation might be heuristics-first, with the other methods as backup. This leverages the speed of heuristics while still achieving high accuracy through the nuanced understanding of the LLM and the pattern recognition of visual analysis. It aligns with the idea of focusing expensive computation where it’s needed most.
Recommendations and Considerations
    1. Start Simple, Then Refine: Begin by implementing the heuristic module with the most clear-cut rules (page number resets, blank pages, obvious email/letter headers, etc.). These will likely catch a fair number of boundaries quickly. Monitor performance on a variety of test PDFs from your law practice. Over time, note the misclassifications and refine the rules or add new ones to cover those cases.
    2. Use Heuristics to Reduce LLM Load: Given that your local LLM is CPU-bound and slow, use the heuristic as a gatekeeper. For example, if the heuristic finds two pages clearly belong together (no signs of break at all), you might skip calling the LLM on that transition. Save LLM queries for when the heuristic finds mixed signals or when the cost of a mistake is high. Remember that every avoided LLM call speeds up the processing.
    3. Avoid Over-Reliance on Single Signal: While speed is important, be cautious about letting one heuristic rule unilaterally decide a boundary unless it’s nearly certain. It’s better to have multiple clues. A voting system doesn’t have to involve all three modules every time, but even within the heuristics, use multiple factors before deciding. For instance, don’t split only because a page had a large blank area at the end – maybe the next page is a continuation that just happened to start at the top. But if a page has a large blank area and the next page has a new letterhead, together those two signals justify a split.
    4. Confidence and Overrides: Implement a notion of confidence for each method:
        ◦ If heuristics gives a high-confidence “no-break” (e.g. strong sentence continuation plus matching headers), you might skip even checking with others.
        ◦ If heuristics gives a high-confidence “break” (e.g. new document cover page detected), you might still double-check with the LLM quickly, but you could bias the decision toward splitting.
        ◦ If the LLM strongly contradicts the heuristic (say heuristics thought it’s a break but LLM finds the text flow continuous), it’s worth investigating that case. It could indicate either an odd document format (needing a new heuristic) or an LLM misinterpretation. In a tie, the visual module (once available) or a conservative default (like “don’t split unless sure”) could apply.
    5. Performance Considerations: If you adopt a pipeline where heuristics run first and others second, the overall latency will be lower than running all methods on all pages. Just ensure that the heuristic analysis itself is efficient – using compiled regexes for keyword detection, precomputing page features (like does it have a page number, does it have an address block) in one OCR pass, etc. The good news is heuristics are usually just string or layout checks and are very fast compared to an ML model.
    6. Adaptability: Since your law firm will encounter diverse documents, consider making the heuristic module configurable or learning-based in the long run. For example, you might allow users to specify certain known patterns (maybe your firm often sees documents that start with “CONFIDENTIAL” or certain letterhead formats – those could be added to a pattern list). Alternatively, as a future improvement, a lightweight machine learning classifier (like Jonas Winkler’s suggestion of training a page classifier for first-page vs othersgithub.com) could be integrated to supplement the hard-coded rules. Such a model would effectively learn heuristics from data. But even without ML training, a carefully crafted set of rules can capture a lot of the same signals.
    7. Testing and Fail-safes: Finally, rigorously test with known multi-document PDFs. If a perfect automatic split is critical, you might incorporate a final review step (even if just logging potential uncertain splits). For instance, if the system isn’t 100% confident on a particular boundary, log it or mark it so that it can be reviewed by a person or reprocessed with more scrutiny. This safety check aligns with the mindset that any error in splitting is costly to fix manuallygithub.com, so the system should err on the side of caution (better to not split when in doubt, rather than split incorrectly).
In summary, design the heuristic module as a collection of complementary rules targeting various hints of a document boundary. Use it to handle obvious cases quickly, and integrate it with your LLM and future visual analysis in a way that balances speed and accuracy. A practical approach is a hybrid pipeline: let heuristics take the first pass and flag probable breaks, then use the LLM/visual methods to verify and handle the edge cases. This way, you leverage the strength of heuristics (speed on simple patterns) while still achieving the robustness provided by deeper analysis. By thoughtfully combining these techniques, you can create a PDF splitter that is both efficient and reliable across the wide range of documents your firm deals with.
Sources:
    • Collins-Thompson & Nickolov (2002), Automatic Document Separation: Achieved 95.6% accuracy using layout and page-number features for segmenting scanned documentswenku.baidu.com.
    • Stack Overflow – “split combined PDF into original documents”: Discusses using PDF page metadata (MediaBox size) to identify breaks in combined scansstackoverflow.com. Sequential pages often share identical dimensions per document, providing a heuristic for splitting.
    • Paperless-NGX Discussion: Developer insights on document separation. Notably, typical first pages have unique headers (addresses, subjects, etc.)github.com, and errors in separation are tedious to correct – emphasizing high accuracygithub.com. Also highlights the challenge of varied document types making one-size-fits-all rules difficultgithub.com.
